{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data\n",
    "trainingSet = pd.read_csv('training.csv')\n",
    "testingSet = pd.read_csv('testing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "x_train = trainingSet.iloc[:, :-1]\n",
    "y_train = trainingSet.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "x_test = testingSet.iloc[:, :-1]\n",
    "y_test = testingSet.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.50764689,  0.26082397,  0.71851375, -1.06490152, -0.96050015,\n",
       "          0.5938403 ,  0.18022769,  0.63153525, -0.9981937 ,  0.98670018],\n",
       "        [ 0.79711445,  1.80061325,  1.31905642, -1.26011122, -1.00492521,\n",
       "         -0.59083354, -0.96779308, -1.65719196, -1.01401087,  2.17958275],\n",
       "        [ 0.85973872, -0.00476808, -0.30571822,  0.19395767,  0.04350629,\n",
       "         -1.46942264,  0.85511814,  0.30133533, -0.59410056,  0.38919339],\n",
       "        [ 1.36939089,  1.60682775,  0.61670184, -0.83670626, -1.09732934,\n",
       "          1.40669341,  2.07963876,  1.06035761, -0.77888598,  1.18512592],\n",
       "        [-0.57607705, -0.14040743,  0.44385348, -0.37653049, -0.44961191,\n",
       "          0.0609053 ,  0.31029916, -0.3265348 , -0.71180371, -0.02813269]]),\n",
       " 0    1\n",
       " 1    0\n",
       " 2    1\n",
       " 3    0\n",
       " 4    1\n",
       " Name: class, dtype: int64)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first five samples\n",
    "x_train[:5], y_train[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.10678062, -0.33325232,  0.02986056, -0.8924032 , -0.94983813,\n",
       "          0.14870248,  0.43522716, -0.49181634,  0.46470936,  0.72556009],\n",
       "        [ 2.04859496,  2.86669614,  1.33170387, -1.43098729, -1.38964626,\n",
       "          1.2349529 ,  2.2407478 , -3.43303578, -0.07709535, -2.12178126],\n",
       "        [-0.32362952, -0.06164417,  0.00477647, -0.67502288, -0.59266062,\n",
       "          0.17852845, -0.58535221, -0.83376742, -1.06627566, -0.54672936],\n",
       "        [-0.68765555, -0.48190269, -1.03695113,  0.74497894,  0.80495189,\n",
       "          0.22117535,  0.08443719, -0.55918017, -0.25928159, -1.42366019],\n",
       "        [-0.75871896, -0.8056027 , -1.61409604,  1.79727275,  1.77430678,\n",
       "          0.46532083,  0.09575282,  0.27216062, -0.26938577, -1.11172009]]),\n",
       " 0    0\n",
       " 1    0\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: class, dtype: int64)"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first five samples\n",
    "x_test[:5], y_test[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn data into tensors\n",
    "import torch\n",
    "\n",
    "x_train = torch.from_numpy(x_train).type(torch.float)\n",
    "y_train = torch.from_numpy(y_train.to_numpy()).type(torch.float)\n",
    "\n",
    "x_test = torch.from_numpy(x_test).type(torch.float)\n",
    "y_test = torch.from_numpy(y_test.to_numpy()).type(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.5076,  0.2608,  0.7185, -1.0649, -0.9605,  0.5938,  0.1802,  0.6315,\n",
       "          -0.9982,  0.9867],\n",
       "         [ 0.7971,  1.8006,  1.3191, -1.2601, -1.0049, -0.5908, -0.9678, -1.6572,\n",
       "          -1.0140,  2.1796],\n",
       "         [ 0.8597, -0.0048, -0.3057,  0.1940,  0.0435, -1.4694,  0.8551,  0.3013,\n",
       "          -0.5941,  0.3892],\n",
       "         [ 1.3694,  1.6068,  0.6167, -0.8367, -1.0973,  1.4067,  2.0796,  1.0604,\n",
       "          -0.7789,  1.1851],\n",
       "         [-0.5761, -0.1404,  0.4439, -0.3765, -0.4496,  0.0609,  0.3103, -0.3265,\n",
       "          -0.7118, -0.0281]]),\n",
       " tensor([1., 0., 1., 0., 1.]))"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first five samples\n",
    "x_train[:5], y_train[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1068, -0.3333,  0.0299, -0.8924, -0.9498,  0.1487,  0.4352, -0.4918,\n",
       "           0.4647,  0.7256],\n",
       "         [ 2.0486,  2.8667,  1.3317, -1.4310, -1.3896,  1.2350,  2.2407, -3.4330,\n",
       "          -0.0771, -2.1218],\n",
       "         [-0.3236, -0.0616,  0.0048, -0.6750, -0.5927,  0.1785, -0.5854, -0.8338,\n",
       "          -1.0663, -0.5467],\n",
       "         [-0.6877, -0.4819, -1.0370,  0.7450,  0.8050,  0.2212,  0.0844, -0.5592,\n",
       "          -0.2593, -1.4237],\n",
       "         [-0.7587, -0.8056, -1.6141,  1.7973,  1.7743,  0.4653,  0.0958,  0.2722,\n",
       "          -0.2694, -1.1117]]),\n",
       " tensor([0., 0., 1., 1., 1.]))"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first five samples\n",
    "x_test[:5], y_test[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataModel(\n",
       "  (layer_1): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (layer_2): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. construct a model class that subclasses nn.Module\n",
    "class dataModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2.create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
    "        # takes in 2 features (X), produces 5 features\n",
    "        self.layer_1 = nn.Linear(in_features=10, out_features=100)\n",
    "        # takes in 5 features, produces 1 feature (y)\n",
    "        self.layer_2 = nn.Linear(in_features=100, out_features=1)\n",
    "\n",
    "    # 3. define a forward method containing the forward pass computation\n",
    "    def forward(self, x):\n",
    "        # return the output of layer_2, a single feature, the same shape as y\n",
    "        # computation goes through layer_1 first then the output of layer_1 goes through layer_2\n",
    "        return self.layer_2(self.layer_1(x))\n",
    "\n",
    "\n",
    "# 4. create an instance of the model and send it to target device\n",
    "model_0 = dataModel().to(device)\n",
    "model_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of predictions: 4012, Shape: torch.Size([4012, 1])\n",
      "length of test samples: 4012, Shape: torch.Size([4012])\n",
      "\n",
      "first 10 predictions:\n",
      "tensor([[-0.1707],\n",
      "        [-0.8624],\n",
      "        [-0.3283],\n",
      "        [-0.2704],\n",
      "        [-0.0677],\n",
      "        [-0.4338],\n",
      "        [-0.2910],\n",
      "        [ 0.0758],\n",
      "        [ 0.0241],\n",
      "        [-0.2348]], grad_fn=<SliceBackward0>)\n",
      "\n",
      "first 10 test labels:\n",
      "tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# make predictions with the model\n",
    "untrained_preds = model_0(x_test.to(device))\n",
    "print(\n",
    "    f\"length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}\")\n",
    "print(f\"length of test samples: {len(y_test)}, Shape: {y_test.shape}\")\n",
    "print(f\"\\nfirst 10 predictions:\\n{untrained_preds[:10]}\")\n",
    "print(f\"\\nfirst 10 test labels:\\n{y_test[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a loss function\n",
    "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
    "loss_fn = nn.BCEWithLogitsLoss()  # BCEWithLogitsLoss = sigmoid built-in\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    # torch.eq() calculates where two tensors are equal\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1707],\n",
       "        [-0.8624],\n",
       "        [-0.3283],\n",
       "        [-0.2704],\n",
       "        [-0.0677]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the frist 5 outputs of the forward pass on the test data\n",
    "y_logits = model_0(x_test.to(device))[:5]\n",
    "y_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4574],\n",
       "        [0.2968],\n",
       "        [0.4187],\n",
       "        [0.4328],\n",
       "        [0.4831]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sigmoid on model logits\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the predicted labels (round the prediction probabilities)\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "\n",
    "# In full\n",
    "y_pred_labels = torch.round(torch.sigmoid(model_0(x_test.to(device))[:5]))\n",
    "\n",
    "# Check for equality\n",
    "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
    "\n",
    "# Get rid of extra dimension\n",
    "y_preds.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.69338, Accuracy: 51.13% | Test loss: 0.65148, Test acc: 64.13%\n",
      "Epoch: 10 | Loss: 0.54142, Accuracy: 75.79% | Test loss: 0.54007, Test acc: 75.85%\n",
      "Epoch: 20 | Loss: 0.51460, Accuracy: 76.06% | Test loss: 0.51781, Test acc: 76.05%\n",
      "Epoch: 30 | Loss: 0.50434, Accuracy: 76.62% | Test loss: 0.50914, Test acc: 76.45%\n",
      "Epoch: 40 | Loss: 0.49914, Accuracy: 76.92% | Test loss: 0.50467, Test acc: 76.77%\n",
      "Epoch: 50 | Loss: 0.49607, Accuracy: 77.07% | Test loss: 0.50194, Test acc: 76.92%\n",
      "Epoch: 60 | Loss: 0.49408, Accuracy: 77.09% | Test loss: 0.50010, Test acc: 77.09%\n",
      "Epoch: 70 | Loss: 0.49272, Accuracy: 77.15% | Test loss: 0.49877, Test acc: 77.17%\n",
      "Epoch: 80 | Loss: 0.49174, Accuracy: 77.04% | Test loss: 0.49778, Test acc: 77.29%\n",
      "Epoch: 90 | Loss: 0.49102, Accuracy: 77.07% | Test loss: 0.49701, Test acc: 77.24%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 100\n",
    "\n",
    "# Put data to target device\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass (model outputs raw logits)\n",
    "    # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n",
    "    y_logits = model_0(x_train).squeeze()\n",
    "    # turn logits -> pred probs -> pred labls\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    # 2. Calculate loss/accuracy\n",
    "    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
    "    #                y_train)\n",
    "    loss = loss_fn(y_logits,  # Using nn.BCEWithLogitsLoss works with raw logits\n",
    "                   y_train)\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Testing\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model_0(x_test).squeeze()\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f34b889236d638c42296b2653e8e50d9b086e8ffa9c688d141e4d8d07d0f3e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
